{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2017-2019 Uber Technologies, Inc.\n",
    "# SPDX-License-Identifier: Apache-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import visdom\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, JitTrace_ELBO, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from utils.mnist_cached import MNISTCached as MNIST\n",
    "from utils.mnist_cached import setup_data_loaders\n",
    "from utils.vae_plots import mnist_test_tsne, plot_llk, plot_vae_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith('1.4.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smole test - run the notebook cells on CI\n",
    "smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = dset.MNIST(root=root, train=True, transform=trans,\n",
    "                    download=download)\n",
    "    test_set = dset.MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the PyTorch module that parameterizes the \n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1  = nn.Linear(784, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # define the forward computation on the image x\n",
    "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
    "        x = x.reshape(-1, 784)\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the PyTorch module that parameterizes the \n",
    "# observation likelihood p(x|z)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1  = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, 784)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = torch.sigmoid(self.fc21(hidden))\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a PyTorch module for the VAE\n",
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of \n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module 'decoder' with Pyro\n",
    "        pyro.module('decoder', self.decoder)\n",
    "        with pyro.plate('data', x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc   = torch.zeros(x.shape[0], self.z_dim, dtype=x.dtype, device=x.device)\n",
    "            z_scale = torch.ones(x.shape[0], self.z_dim, dtype=x.dtype, device=x.device)\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample('latent', dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder.forward(z)\n",
    "            # score against actual images\n",
    "            pyro.sample('obs', dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))\n",
    "            #return the loc so we can visualize it later\n",
    "            return loc_img\n",
    "\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module 'encoder' with Pyro\n",
    "        pyro.module('encoder', self.encoder)\n",
    "        with pyro.plate('data', x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder.forward(x)\n",
    "            # sample the latent code Z\n",
    "            pyro.sample('latent', dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # samle in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        #decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # clear param store\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    # setup MNIST data loaders\n",
    "    # train_loader, test_loader\n",
    "    train_loader, test_loader = setup_data_loaders(MNIST, use_cuda=args.cuda, batch_size=256)\n",
    "\n",
    "    # setup the VAE\n",
    "    vae = VAE(use_cuda=args.cuda)\n",
    "\n",
    "    # setup the optimizer\n",
    "    adam_args = {'lr': args.learning_rate}\n",
    "    optimizer = Adam(adam_args)\n",
    "\n",
    "    # setup the inference algorithm\n",
    "    elbo = JitTrace_ELBO() if args.jit else Trace_ELBO()\n",
    "    svi = SVI(vae.model, vae.guide, optimizer, loss=elbo)\n",
    "\n",
    "    # setup visdom for visualization\n",
    "    if args.visdom_flag:\n",
    "        vis = visdom.Visdom()\n",
    "\n",
    "    train_elbo = []\n",
    "    test_elbo = []\n",
    "    # training loop\n",
    "    for epoch in range(args.num_epochs):\n",
    "        # initialize loss accumulator\n",
    "        epoch_loss = 0\n",
    "        # do a training epoch over each mini-batch x returned\n",
    "        # by the data loader\n",
    "        for x, _ in train_loader:\n",
    "            # if on GPU put mini-batch into CUDA memory\n",
    "            if args.cuda:\n",
    "                x = x.cuda()\n",
    "            # do ELBO gradient and accumulate loss\n",
    "            epoch_loss += svi.step(x)\n",
    "        \n",
    "        # report training diagnostics\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print('[epoch %03d] average training loss: %.4f' % (epoch, total_epoch_loss_train))\n",
    "\n",
    "        if epoch % args.test_frequency == 0:\n",
    "            # initialize loss accumulator\n",
    "            test_loss = 0.\n",
    "            # compute the loss over the entire test set\n",
    "            for i, (x, _) in enumerate(test_loader):\n",
    "                # if on GPU put mini-batch into CUDA memory\n",
    "                if args.cuda:\n",
    "                    x = x.cuda()\n",
    "                # compute ELBO estimate and accumulate loss\n",
    "                test_loss += svi.evaluate_loss(x)\n",
    "\n",
    "                # pick three random test images from the first mini-batch and \n",
    "                # visualize how well we're reconstructing them\n",
    "                if i == 0:\n",
    "                    if args.visdom_flag:\n",
    "                        plot_vae_samples(vae, vis)\n",
    "                        reco_indices = np.random.randint(0, x.shape[0], 3)\n",
    "                        for index in reco_indices:\n",
    "                            test_img = x[index, :]\n",
    "                            reco_img = vae.reconstruct_img(test_img)\n",
    "                            vis.image(test_img.reshape(28, 28).detach().cpu().numpy(), opts={'caption': 'test image'})\n",
    "                            vis.image(reco_img.reshape(28, 28).detach().cpu().numpy(), opts={'caption': 'reconstructed image'})\n",
    "\n",
    "            # report test diagnostics\n",
    "            normalizer_test = len(test_loader.dataset)\n",
    "            total_epoch_loss_test = test_loss / normalizer_test\n",
    "            test_elbo.append(total_epoch_loss_test)\n",
    "            print('[epoch %03d] average test loss: %.4f' % (epoch, total_epoch_loss_test))\n",
    "        \n",
    "        if epoch == args.tsne_iter:\n",
    "            mnist_test_tsne(vae=vae, test_loader=test_loader)\n",
    "            plot_llk(np.array(train_elbo), np.array(test_elbo))\n",
    "    \n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-n NUM_EPOCHS] [-tf TEST_FREQUENCY]\n                             [-lf LEARNING_RATE] [--cuda] [--jit] [-visdom]\n                             [-i-tsne TSNE_ITER]\nipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"fcb578a3-1ea9-4600-b178-283b64f52fd4\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/tmp/tmp-11967ZCpcG8g69sVd.json\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    assert pyro.__version__.startswith('1.5.0')\n",
    "    # parse command line arguments\n",
    "    parser = argparse.ArgumentParser(description='parse args')\n",
    "    parser.add_argument('-n', '--num-epochs', default=101, type=int, help='number of training epochs')\n",
    "    parser.add_argument('-tf', '--test-frequency', default=5, type=int, help='how often we evaluate the test set')\n",
    "    parser.add_argument('-lf', '--learning-rate', default=1.0e-3, type=float, help='learning rate')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False, help='whether to use cuda')\n",
    "    parser.add_argument('--jit', action='store_true', default=False, help='whether to use PyTorch jit')\n",
    "    parser.add_argument('-visdom', '--visdom_flag', action='store_true', help='Whether plotting in visdom is desired')\n",
    "    parser.add_argument('-i-tsne', '--tsne_iter', default=100, type=int, help='epoch when tsne visualization runs')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}